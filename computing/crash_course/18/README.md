# Operating Systems
[Video Link](https://youtu.be/26QPDBe-NB8)

Computers in the 1940s and early 1950s ran one program at a time. A program (in the form of punch cards) would be fed into a computer by hand. The computer would read and run the program, spit out some output and halt. This manual process worked fine when computers were slow, and running a program often took hours, days, or weeks.

As computers increased in speed, the process of manually feeding programs into computers started to take longer than it took the programs themselves to run. It became necessary for computers to operate themselves, and so [operating systems](../glossary/README.md#operating-system) were born.

Operating systems are just programs. Special privileges on the hardware allow them to run and manage other programs. They are typically the first program to start when a computer boots and all subsequent programs are launched by the OS. They got their start in the 1950s, as computers became more widespread and powerful. The very first OSs augmented the mundane, manual task of loading programs by hand. Instead of being given one program at a time, computers could be loaded with batches of them. When a computer completed a program, it would automatically start the next one. This eliminated the downtime present in manual workflows. This process is known as [batch processing](../glossary/README.md#batch-processing).

As computers grew faster, they also grew cheaper, leading to more widespread adoption (particularly in universities and governmet offices). It wasn't long before people began to share software. However, in the era of one-off computers programmers only ever had to write code for a single machine. As computer usage proliferated, there was no guarantee that computers would have the same hardware configuration (cpu, peripherals, etc). Programmers would have to write their programs to interface with every model of printer and other peripherals. Interfacing with early peripherals was very low level, requiring programmers to known intimate hardware details about each device. On top of that, programmers rarely had access to every model of a peripheral to test their code on.

Programmers had to write the code as best they could, often by simply reading manuals, and hope that it would work as intended when shared. To make it easier for programmers, operating systems were implemented as intermediaries between software programs and hardware peripherals. They provided a software abstraction through [APIs](../glossary/README.md#api) called [device drivers](../glossary/README.md#device-driver). Drivers allow programmers to talk to common input and output (I/O) hardware using standardized mechanisms.

By the end of the 1950s, computers had gotten so fast they were often idle waiting for slow mechanical processes such as printers and punch card readers. While programs were blocked on I/O the expensive processors sat idle.

In the late 1950s, the University of Manchester in the UK began work on a [supercomputer](../glossary/README.md#supercomputer) called [Atlas](https://en.wikipedia.org/wiki/Atlas_(computer)) (one of the first in the world). Knowing that it would be an incredibly fast computer, Atlas's creators needed a way to make maximum use of the machine. Their solution was a program called the _Atlas Supervisor_, finished in 1962. This operating system not only loaded programs automatically, like earlier batch systems, but could also run several at the same time on its single CPU. It did this through clever [scheduling](../glossary/README.md#scheduling). By scheduling programs, Atlas could have one program running calculations on the CPU, while another was printing out data, and yet another reading in data from a punch tape. This strategy allowed many programs to be in progress at all once, sharing time on a single CPU.

This ability enabled by the operating system is called [multitasking](../glossary/README.md#multitasking). The catch to multitasking is that each running program needs memory, and data must be preserved when switching to another program. The solution to this dilemma is to allocate each program its own block of memory. If a program requests more memory it is the operating system that determines if the request can be granted, and to deliver on the request. This approach also means that a program may be allocated non-sequential blocks of memory. To hide the complexity of program memory allocation, operating systems [virtualize memory locations](../glossary/README.md#virtual-memory). With virtual memory programs can always assume their memory always starts at address 0, keeping things simple and consistent. The actual, physical location in computer memory is hidden and abstracted by the operating system.

Virtual memory allows programs to have flexible memory sizes, called _dynamic memory allocation_, that appear to be continuous to them. It simplifies everything and offers tremendous flexibility to the operating system in running multiple programs simultaneously. Another benefit of allocating each program its own memory is that they are better isolated from one another. If a program encounters a bug and starts writing garbage data it can only trash its own memory and not that of other programs. This feature is called [memory protection](../glossary/README.md#memory-protection). This strategy is also really useful in protecting against malicious software: it is generally not desired to allow programs the ability to read or modify the memory of other programs.

Atlas had both virtual and protected memory - it was the first computer and OS to support these features. By the 1970s computers were sufficiently fast and cheap. Institutions like a university could buy a computer and let students use it. It was not only fast enough to run several programs at once, but also give several users simultaneous, interactive access. This was done through a [terminal](../glossary/README.md#computer-terminal), which is a keyboard and screen that connects to a big computer, but doesn't contain any processing power itself. Now operating systems had to handle not just multiple programs, but also multiple users.

To serve this new need operating systems were developed that offered [time-sharing](../glossary/README.md#time-sharing). With time-sharing each individual user was only allowed to utilize a small fraction of the computer's resources (processor, memory, etc.). Because computers are so fast, even getting just 1/50th of its resources was enough for individuals to complete many tasks. The most influential of early time-sharing operating systems was [Multics](https://en.wikipedia.org/wiki/Multics), or _Multiplexed Information and Computing Service_, released in 1969. Multics was the first major operating system designed to be secure from the outset.

[Dennis Ritchie](https://en.wikipedia.org/wiki/Dennis_Ritchie), one of the researchers working on Multics, once said: "One of the obvious things that went wrong with Multics as a commercial success was just that it was sort of over-engineered in a sense. There was just too much in it." This led Dennis, and another Multics researcher, [Ken Thompson](https://en.wikipedia.org/wiki/Ken_Thompson), to strike out on their own and build a new, lean operating system called [Unix](../glossary/README.md#unix). They wanted to separte the OS into two parts:
1. The [kernel](../glossary/README.md#kernel): The core functionality of the OS, things like memory management, multitasking, and dealing with I/O.
2. A wide array of useful tools that came bundled with, but not part of the kernel, like programs and libraries.

Building a compact,lean kernel meant intentionally leaving some functionality out. [Tom Van Vleck](https://en.wikipedia.org/wiki/Tom_Van_Vleck), another Multics developer, recalled: "I remarked to Dennis that easiliy half the code I was writing in Multics was error recovery code. He said, 'We left all that stuff out of Unix. If there's an error, we have this routine called Panic, and when it is called, the machine crashes, and you holler down the hall "Hey, reboot it."'" This is where the term [kernel panic](https://en.wikipedia.org/wiki/Kernel_panic) comes from. This happens when the kernel crashes, has no recourse to recover, and so calls a function called _panic_. Originally all this function did was print the word "panic" and then enter an infinite loop. This simplicity meant that Unix could be run on cheaper and more diverse hardware, making it popular inside [Bell Labs](https://en.wikipedia.org/wiki/Bell_Labs) where Dennis and Ken worked.

As more developers started using Unix to build and run their own programs, the number of contributed tools grew. Soon after its release in 1971, it gained compilers for different programming langages and even a word processor, quickly making it one of the most popular OSes of the 1970s and 1980s. By the early 1980s the cost of a basic computer had fallen to the point where individual people could afford one, called a [personal or home computer](../glossary/README.md#personal-computer). These were much simpler than the big mainframes found at universities, corporations, and governments - so their operating systems had to be equally simple.

[Microsoft's Disk Operating System](https://en.wikipedia.org/wiki/MS-DOS) (or MS-DOS) was just 160 kilobytes, allowing it to fit onto a single disk. First released in 1981, it became the most popular OS for early home computers, even though it lacked features like multitasking and protected memory. This meant that programs could, and would, regularly crash the system. While annoying, this was an acceptable tradeoff, as users could just their own computers off and on again.

Even early versions of [Windows](https://en.wikipedia.org/wiki/Microsoft_Windows), first released by Microsoft in 1985 and which dominated the OS scene throughout the 1990s, lacked strong memory protection. When programs misbehaved users would get the [blue screen of death](https://en.wikipedia.org/wiki/Blue_screen_of_death), a sign that a program had crashed so badly it took down the whole operating system.

![A blue screen of death, as appears on Windows 9x](./Windows_9X_BSOD.png)
<br /><br />

Newer versions of Windows have better protections and usually don't crash that often.

Today computers run modern operating systems like [Mac OS X](https://en.wikipedia.org/wiki/MacOS), [Windows 10](https://en.wikipedia.org/wiki/Windows_10), [Linux](https://en.wikipedia.org/wiki/Linux), [iOS](https://en.wikipedia.org/wiki/IOS), and [Android](https://en.wikipedia.org/wiki/Android_(operating_system)). Even though computers today are most often used by just a single person their OSes all have multitasking and virtual and protected memory - so they can run many programs at once. This wouldn't be possible without those decades of research and development on operating systems, and of course the proper memory to store those programs.

| [Previous: Integrated Circuits & Moore's Law](../17/README.md) | [Table of Contents](../README.md#table-of-contents) | Next |
